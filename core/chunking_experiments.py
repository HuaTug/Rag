#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Chunking Strategy Experiments for RAG System

Compare different chunking strategies and evaluate their performance.
"""

import time
import json
import logging
from typing import List, Dict, Any, Tuple
from dataclasses import dataclass, asdict
import matplotlib.pyplot as plt
import pandas as pd
from enhanced_text_processor import EnhancedTextProcessor, TextChunk

@dataclass
class ChunkingConfig:
    """Chunking configuration for experiments"""
    name: str
    chunk_size: int
    chunk_overlap: int
    min_chunk_size: int
    max_chunk_size: int
    enable_chinese_segmentation: bool = True
    enable_keyword_extraction: bool = True
    preserve_code_blocks: bool = True

@dataclass
class ExperimentResult:
    """Results from chunking experiment"""
    config_name: str
    total_chunks: int
    avg_chunk_size: int
    avg_token_count: float
    avg_importance_score: float
    processing_time: float
    chunks_in_optimal_range: int  # 20-500 tokens
    language_distribution: Dict[str, int]
    
class ChunkingExperiments:
    """Chunking strategy experiments and evaluation"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # Predefined experimental configurations
        self.experiment_configs = [
            ChunkingConfig("Small_Chunks", 400, 50, 50, 600),
            ChunkingConfig("Medium_Chunks", 800, 100, 100, 1200),
            ChunkingConfig("Large_Chunks", 1200, 150, 150, 1800),
            ChunkingConfig("High_Overlap", 800, 200, 100, 1200),
            ChunkingConfig("Low_Overlap", 800, 50, 100, 1200),
            ChunkingConfig("No_Chinese_Seg", 800, 100, 100, 1200, False),
            ChunkingConfig("No_Keywords", 800, 100, 100, 1200, True, False),
        ]
    
    def run_experiment(self, test_data: List[Dict[str, Any]], 
                      configs: List[ChunkingConfig] = None) -> List[ExperimentResult]:
        """Run chunking experiments with different configurations"""
        
        if configs is None:
            configs = self.experiment_configs
        
        results = []
        
        self.logger.info(f" Starting chunking experiments with {len(configs)} configurations")
        
        for config in configs:
            self.logger.info(f" Testing configuration: {config.name}")
            
            # Create processor with current config
            processor_config = asdict(config)
            processor_config.pop('name')  # Remove name field
            processor = EnhancedTextProcessor(processor_config)
            
            # Measure processing time
            start_time = time.time()
            chunks = processor.process_search_results(test_data)
            processing_time = time.time() - start_time
            
            # Calculate metrics
            result = self._calculate_metrics(config.name, chunks, processing_time)
            results.append(result)
            
            self.logger.info(f" {config.name}: {result.total_chunks} chunks, "
                           f"{result.avg_chunk_size} avg size, "
                           f"{result.processing_time:.2f}s")
        
        return results
    
    def _calculate_metrics(self, config_name: str, chunks: List[TextChunk], 
                          processing_time: float) -> ExperimentResult:
        """Calculate metrics for experiment result"""
        
        if not chunks:
            return ExperimentResult(
                config_name=config_name,
                total_chunks=0,
                avg_chunk_size=0,
                avg_token_count=0.0,
                avg_importance_score=0.0,
                processing_time=processing_time,
                chunks_in_optimal_range=0,
                language_distribution={}
            )
        
        # Basic metrics
        total_chunks = len(chunks)
        avg_chunk_size = sum(len(chunk.content) for chunk in chunks) // total_chunks
        avg_token_count = sum(chunk.token_count for chunk in chunks) / total_chunks
        avg_importance_score = sum(chunk.importance_score for chunk in chunks) / total_chunks
        
        # Quality metrics
        chunks_in_optimal_range = sum(1 for chunk in chunks 
                                    if 20 <= chunk.token_count <= 500)
        
        # Language distribution
        language_dist = {}
        for chunk in chunks:
            lang = chunk.language
            language_dist[lang] = language_dist.get(lang, 0) + 1
        
        return ExperimentResult(
            config_name=config_name,
            total_chunks=total_chunks,
            avg_chunk_size=avg_chunk_size,
            avg_token_count=avg_token_count,
            avg_importance_score=avg_importance_score,
            processing_time=processing_time,
            chunks_in_optimal_range=chunks_in_optimal_range,
            language_distribution=language_dist
        )
    
    def compare_results(self, results: List[ExperimentResult]) -> pd.DataFrame:
        """Compare experiment results in a DataFrame"""
        
        data = []
        for result in results:
            data.append({
                'Configuration': result.config_name,
                'Total Chunks': result.total_chunks,
                'Avg Chunk Size': result.avg_chunk_size,
                'Avg Token Count': f"{result.avg_token_count:.1f}",
                'Avg Importance Score': f"{result.avg_importance_score:.2f}",
                'Processing Time (s)': f"{result.processing_time:.2f}",
                'Optimal Range %': f"{(result.chunks_in_optimal_range/result.total_chunks*100):.1f}%" if result.total_chunks > 0 else "0%"
            })
        
        df = pd.DataFrame(data)
        return df
    
    def visualize_results(self, results: List[ExperimentResult], save_path: str = None):
        """Visualize experiment results"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('Chunking Strategy Comparison', fontsize=16)
        
        configs = [r.config_name for r in results]
        
        # 1. Total chunks comparison
        total_chunks = [r.total_chunks for r in results]
        axes[0, 0].bar(configs, total_chunks)
        axes[0, 0].set_title('Total Chunks Generated')
        axes[0, 0].set_ylabel('Number of Chunks')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. Average token count
        avg_tokens = [r.avg_token_count for r in results]
        axes[0, 1].bar(configs, avg_tokens)
        axes[0, 1].set_title('Average Token Count')
        axes[0, 1].set_ylabel('Tokens')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. Processing time
        proc_times = [r.processing_time for r in results]
        axes[1, 0].bar(configs, proc_times)
        axes[1, 0].set_title('Processing Time')
        axes[1, 0].set_ylabel('Seconds')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. Quality score (optimal range percentage)
        quality_scores = [r.chunks_in_optimal_range/r.total_chunks*100 if r.total_chunks > 0 else 0 
                         for r in results]
        axes[1, 1].bar(configs, quality_scores)
        axes[1, 1].set_title('Chunks in Optimal Range (20-500 tokens)')
        axes[1, 1].set_ylabel('Percentage (%)')
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            self.logger.info(f" Visualization saved to {save_path}")
        
        plt.show()
    
    def save_results(self, results: List[ExperimentResult], filepath: str):
        """Save experiment results to JSON file"""
        
        results_data = []
        for result in results:
            results_data.append(asdict(result))
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"üíæ Results saved to {filepath}")
    
    def load_results(self, filepath: str) -> List[ExperimentResult]:
        """Load experiment results from JSON file"""
        
        with open(filepath, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
        
        results = []
        for data in results_data:
            results.append(ExperimentResult(**data))
        
        self.logger.info(f"üìÇ Results loaded from {filepath}")
        return results

def create_test_dataset() -> List[Dict[str, Any]]:
    """Create a comprehensive test dataset for experiments"""
    
    return [
        {
            "title": "‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÂèëÂ±ïÁé∞Áä∂‰∏éË∂ãÂäø",
            "content": """
            ‰∫∫Â∑•Êô∫ËÉΩÔºàArtificial Intelligence, AIÔºâ‰Ωú‰∏∫21‰∏ñÁ∫™ÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÈù©ÂëΩ‰πã‰∏ÄÔºåÊ≠£Âú®Ê∑±ÂàªÊîπÂèòÁùÄÊàë‰ª¨ÁöÑÁîüÊ¥ªÂíåÂ∑•‰ΩúÊñπÂºè„ÄÇ
            
            ## ÊäÄÊúØÂèëÂ±ïÁé∞Áä∂
            
            ÁõÆÂâçÔºåAIÊäÄÊúØ‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê†∏ÂøÉÈ¢ÜÂüüÔºö
            
            1. **Êú∫Âô®Â≠¶‰π†ÔºàMachine LearningÔºâ**ÔºöÈÄöËøáÁÆóÊ≥ïËÆ©ËÆ°ÁÆóÊú∫‰ªéÊï∞ÊçÆ‰∏≠Â≠¶‰π†Ê®°Âºè
            2. **Ê∑±Â∫¶Â≠¶‰π†ÔºàDeep LearningÔºâ**ÔºöÂü∫‰∫éÁ•ûÁªèÁΩëÁªúÁöÑÂ≠¶‰π†ÊñπÊ≥ï
            3. **Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÔºàNLPÔºâ**ÔºöËÆ©ËÆ°ÁÆóÊú∫ÁêÜËß£ÂíåÁîüÊàê‰∫∫Á±ªËØ≠Ë®Ä
            4. **ËÆ°ÁÆóÊú∫ËßÜËßâÔºàComputer VisionÔºâ**ÔºöËÆ©ËÆ°ÁÆóÊú∫"ÁúãÊáÇ"ÂõæÂÉèÂíåËßÜÈ¢ë
            
            ### ‰∏ªË¶ÅÂ∫îÁî®Âú∫ÊôØ
            
            - Êô∫ËÉΩÊé®ËçêÁ≥ªÁªüÔºöÂ¶ÇÁîµÂïÜÂπ≥Âè∞ÁöÑÂïÜÂìÅÊé®Ëçê
            - ËØ≠Èü≥Âä©ÊâãÔºöSiri„ÄÅAlexaÁ≠âÊô∫ËÉΩËØ≠Èü≥‰∫§‰∫íÁ≥ªÁªü
            - Ëá™Âä®È©æÈ©∂ÔºöTesla„ÄÅWaymoÁ≠âÂÖ¨Âè∏ÁöÑÊó†‰∫∫È©æÈ©∂ÊäÄÊúØ
            - ÂåªÁñóËØäÊñ≠ÔºöAIËæÖÂä©ÂåªÁîüËøõË°åÁñæÁóÖËØäÊñ≠ÂíåÊ≤ªÁñóÊñπÊ°àÂà∂ÂÆö
            
            ## Êú™Êù•ÂèëÂ±ïË∂ãÂäø
            
            1. **Â§öÊ®°ÊÄÅAI**ÔºöÁªìÂêàÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅËØ≠Èü≥Á≠âÂ§öÁßçÊï∞ÊçÆÁ±ªÂûã
            2. **ËæπÁºòËÆ°ÁÆó**ÔºöÂ∞ÜAIËÆ°ÁÆóËÉΩÂäõÈÉ®ÁΩ≤Âà∞ËÆæÂ§áÁ´Ø
            3. **ÂèØËß£ÈáäAI**ÔºöËÆ©AIÁöÑÂÜ≥Á≠ñËøáÁ®ãÊõ¥Âä†ÈÄèÊòéÂíåÂèØÁêÜËß£
            4. **AI‰º¶ÁêÜ**ÔºöÁ°Æ‰øùAIÊäÄÊúØÁöÑÂÖ¨Âπ≥ÊÄßÂíåÂÆâÂÖ®ÊÄß
            
            The future of AI looks promising with continuous advancements in hardware and algorithms.
            """,
            "url": "https://example.com/ai-trends"
        },
        {
            "title": "Python WebÂºÄÂèëÊúÄ‰Ω≥ÂÆûË∑µ",
            "content": """
            Python‰Ωú‰∏∫‰∏ÄÈó®‰ºòÁßÄÁöÑÁºñÁ®ãËØ≠Ë®ÄÔºåÂú®WebÂºÄÂèëÈ¢ÜÂüüÊúâÁùÄÂπøÊ≥õÁöÑÂ∫îÁî®„ÄÇÊú¨ÊñáÂ∞Ü‰ªãÁªçPython WebÂºÄÂèëÁöÑÊúÄ‰Ω≥ÂÆûË∑µ„ÄÇ
            
            ## Ê°ÜÊû∂ÈÄâÊã©
            
            ### Django
            DjangoÊòØ‰∏Ä‰∏™È´òÁ∫ßÁöÑPython WebÊ°ÜÊû∂ÔºåÈÅµÂæ™"Á∫¶ÂÆö‰ºò‰∫éÈÖçÁΩÆ"ÁöÑÂéüÂàôÔºö
            
            ```python
            from django.http import HttpResponse
            from django.shortcuts import render
            
            def index(request):
                return HttpResponse("Hello, world!")
            ```
            
            **‰ºòÁÇπ**Ôºö
            - ÂäüËÉΩÂÆåÊï¥ÔºåÂåÖÂê´ORM„ÄÅÊ®°ÊùøÂºïÊìé„ÄÅÁî®Êà∑ËÆ§ËØÅÁ≠â
            - ÂÆâÂÖ®ÊÄßÈ´òÔºåÂÜÖÁΩÆCSRF‰øùÊä§„ÄÅSQLÊ≥®ÂÖ•Èò≤Êä§Á≠â
            - Á§æÂå∫Ê¥ªË∑ÉÔºåÊñáÊ°£ÂÆåÂñÑ
            
            ### Flask
            FlaskÊòØ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑWebÊ°ÜÊû∂Ôºö
            
            ```python
            from flask import Flask
            app = Flask(__name__)
            
            @app.route('/')
            def hello_world():
                return 'Hello, World!'
            ```
            
            **ÁâπÁÇπ**Ôºö
            - ÁÆÄÂçïÊòìÂ≠¶ÔºåÈÄÇÂêàÂ∞èÂûãÈ°πÁõÆ
            - ÁÅµÊ¥ªÊÄßÈ´òÔºåÂèØ‰ª•Ëá™Áî±ÈÄâÊã©ÁªÑ‰ª∂
            - Êâ©Â±ï‰∏∞ÂØåÔºåÁîüÊÄÅÁ≥ªÁªüÂÆåÂñÑ
            
            ## ÂºÄÂèëËßÑËåÉ
            
            1. **‰ª£Á†ÅÁªìÊûÑ**ÔºöÈááÁî®MVCÊàñMVTÊ®°Âºè
            2. **Êï∞ÊçÆÂ∫ìËÆæËÆ°**ÔºöÂêàÁêÜËÆæËÆ°Ë°®ÁªìÊûÑÔºå‰ΩøÁî®Á¥¢Âºï‰ºòÂåñÊü•ËØ¢
            3. **APIËÆæËÆ°**ÔºöÈÅµÂæ™RESTfulËßÑËåÉ
            4. **ÊµãËØï**ÔºöÁºñÂÜôÂçïÂÖÉÊµãËØïÂíåÈõÜÊàêÊµãËØï
            5. **ÈÉ®ÁΩ≤**Ôºö‰ΩøÁî®DockerÂÆπÂô®ÂåñÈÉ®ÁΩ≤
            
            ## ÊÄßËÉΩ‰ºòÂåñ
            
            - ‰ΩøÁî®ÁºìÂ≠òÔºàRedis„ÄÅMemcachedÔºâ
            - Êï∞ÊçÆÂ∫ìÊü•ËØ¢‰ºòÂåñ
            - ÈùôÊÄÅÊñá‰ª∂CDNÂä†ÈÄü
            - ÂºÇÊ≠•Â§ÑÁêÜÔºàCeleryÔºâ
            """,
            "url": "https://example.com/python-web-best-practices"
        },
        {
            "title": "Âå∫ÂùóÈìæÊäÄÊúØÂéüÁêÜ‰∏éÂ∫îÁî®",
            "content": """
            Âå∫ÂùóÈìæÔºàBlockchainÔºâÊòØ‰∏ÄÁßçÂàÜÂ∏ÉÂºèË¥¶Êú¨ÊäÄÊúØÔºåÂÖ∑ÊúâÂéª‰∏≠ÂøÉÂåñ„ÄÅ‰∏çÂèØÁØ°Êîπ„ÄÅÈÄèÊòéÂÖ¨ÂºÄÁ≠âÁâπÁÇπ„ÄÇ
            
            ## Ê†∏ÂøÉÊ¶ÇÂøµ
            
            ### Âå∫ÂùóÁªìÊûÑ
            ÊØè‰∏™Âå∫ÂùóÂåÖÂê´‰ª•‰∏ã‰ø°ÊÅØÔºö
            - Âå∫ÂùóÂ§¥ÔºàBlock HeaderÔºâ
            - ‰∫§ÊòìÊï∞ÊçÆÔºàTransaction DataÔºâ
            - Êó∂Èó¥Êà≥ÔºàTimestampÔºâ
            - Ââç‰∏Ä‰∏™Âå∫ÂùóÁöÑÂìàÂ∏åÂÄºÔºàPrevious HashÔºâ
            
            ### ÂÖ±ËØÜÊú∫Âà∂
            1. **Â∑•‰ΩúÈáèËØÅÊòéÔºàPoWÔºâ**ÔºöÊØîÁâπÂ∏ÅÈááÁî®ÁöÑÂÖ±ËØÜÊú∫Âà∂
            2. **ÊùÉÁõäËØÅÊòéÔºàPoSÔºâ**Ôºö‰ª•Â§™Âùä2.0ÈááÁî®ÁöÑÊú∫Âà∂
            3. **ÂßîÊâòÊùÉÁõäËØÅÊòéÔºàDPoSÔºâ**ÔºöEOSÁ≠âÂπ≥Âè∞‰ΩøÁî®
            
            ## ÊäÄÊúØÁâπÁÇπ
            
            - **Âéª‰∏≠ÂøÉÂåñ**ÔºöÊ≤°Êúâ‰∏≠Â§ÆÊéßÂà∂Êú∫ÊûÑ
            - **‰∏çÂèØÁØ°Êîπ**ÔºöÂéÜÂè≤ËÆ∞ÂΩïÊó†Ê≥ï‰øÆÊîπ
            - **ÈÄèÊòéÊÄß**ÔºöÊâÄÊúâ‰∫§ÊòìÂÖ¨ÂºÄÂèØÊü•
            - **ÂÆâÂÖ®ÊÄß**ÔºöÂØÜÁ†ÅÂ≠¶‰øùËØÅÊï∞ÊçÆÂÆâÂÖ®
            
            ## Â∫îÁî®È¢ÜÂüü
            
            ### ÈáëËûçÊúçÂä°
            - Êï∞Â≠óË¥ßÂ∏ÅÔºöBitcoin„ÄÅEthereumÁ≠â
            - Ë∑®Â¢ÉÊîØ‰ªòÔºöÈôç‰ΩéËΩ¨Ë¥¶ÊàêÊú¨ÂíåÊó∂Èó¥
            - ‰æõÂ∫îÈìæÈáëËûçÔºöÊèêÈ´òÈÄèÊòéÂ∫¶ÂíåÊïàÁéá
            
            ### ÂÖ∂‰ªñÂ∫îÁî®
            - ‰æõÂ∫îÈìæÁÆ°ÁêÜÔºöÂïÜÂìÅÊ∫ØÊ∫êÂíåÈò≤‰º™
            - Êï∞Â≠óË∫´‰ªΩÔºöË∫´‰ªΩËÆ§ËØÅÂíåÈöêÁßÅ‰øùÊä§
            - Êô∫ËÉΩÂêàÁ∫¶ÔºöËá™Âä®ÊâßË°åÂêàÁ∫¶Êù°Ê¨æ
            - ÁâàÊùÉ‰øùÊä§ÔºöÊï∞Â≠ó‰ΩúÂìÅÁ°ÆÊùÉ
            
            Blockchain technology is revolutionizing various industries beyond cryptocurrency.
            """,
            "url": "https://example.com/blockchain-principles"
        }
    ]

def run_comprehensive_experiment():
    """Run comprehensive chunking experiments"""
    
    print(" Starting Comprehensive Chunking Experiments")
    print("=" * 60)
    
    # Initialize experiment framework
    experiments = ChunkingExperiments()
    
    # Create test dataset
    test_data = create_test_dataset()
    print(f" Test dataset: {len(test_data)} documents")
    
    # Run experiments
    results = experiments.run_experiment(test_data)
    
    # Display results
    print("\nExperiment Results:")
    print("=" * 60)
    
    df = experiments.compare_results(results)
    print(df.to_string(index=False))
    
    # Find best configuration
    best_config = max(results, key=lambda r: r.chunks_in_optimal_range/r.total_chunks if r.total_chunks > 0 else 0)
    print(f"\nüèÜ Best Configuration: {best_config.config_name}")
    print(f"   - Optimal Range Coverage: {best_config.chunks_in_optimal_range/best_config.total_chunks*100:.1f}%")
    print(f"   - Average Importance Score: {best_config.avg_importance_score:.2f}")
    print(f"   - Processing Time: {best_config.processing_time:.2f}s")
    
    # Save results
    experiments.save_results(results, "chunking_experiment_results.json")
    
    # Visualize results (optional, requires matplotlib)
    try:
        experiments.visualize_results(results, "chunking_comparison.png")
    except ImportError:
        print(" Matplotlib not available, skipping visualization")
    
    return results

if __name__ == "__main__":
    # Setup logging
    logging.basicConfig(level=logging.INFO, 
                       format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Run experiments
    results = run_comprehensive_experiment()