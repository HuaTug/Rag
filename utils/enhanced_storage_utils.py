#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¢å¼ºå­˜å‚¨å·¥å…·ç±»

æä¾›ç®€åŒ–çš„æ¥å£æ¥ä½¿ç”¨å¢å¼ºæ–‡æœ¬å¤„ç†å’Œå‘é‡å­˜å‚¨åŠŸèƒ½
"""

import logging
import sys
import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from service.enhanced_rag_processor import EnhancedRAGProcessor
from service.channel_framework import SearchResult

class EnhancedStorageManager:
    """å¢å¼ºå­˜å‚¨ç®¡ç†å™¨ - ç®€åŒ–çš„æ¥å£"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–å¢å¼ºå­˜å‚¨ç®¡ç†å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ–‡æœ¬å¤„ç†å’Œå­˜å‚¨å‚æ•°
        """
        self.config = config or {}
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # é»˜è®¤é…ç½®
        default_config = {
            "chunk_size": 800,
            "chunk_overlap": 100,
            "enable_chinese_segmentation": True,
            "enable_keyword_extraction": True,
            "preserve_code_blocks": True,
            "similarity_threshold": 0.7,
            "min_chunk_size": 100,
            "max_chunk_size": 1200
        }
        
        # åˆå¹¶é…ç½®
        self.config = {**default_config, **self.config}
        
        # åˆå§‹åŒ–RAGå¤„ç†å™¨
        self.rag_processor = EnhancedRAGProcessor(config=self.config)
        
        self.logger.info("âœ… å¢å¼ºå­˜å‚¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def store_search_results(self, search_results: List[SearchResult]) -> bool:
        """
        å­˜å‚¨æœç´¢ç»“æœï¼ˆä¸»è¦æ¥å£ï¼‰
        
        Args:
            search_results: æœç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        return await self.rag_processor.store_search_results_with_enhanced_processing(search_results)
    
    async def store_raw_data(self, raw_data: List[Dict[str, Any]]) -> bool:
        """
        å­˜å‚¨åŸå§‹æ•°æ®ï¼ˆè‡ªåŠ¨è½¬æ¢ä¸ºSearchResultæ ¼å¼ï¼‰
        
        Args:
            raw_data: åŸå§‹æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åº”åŒ…å«title, content, urlç­‰å­—æ®µ
            
        Returns:
            bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        try:
            # è½¬æ¢ä¸ºSearchResultæ ¼å¼
            search_results = []
            for data in raw_data:
                result = SearchResult(
                    title=data.get('title', ''),
                    content=data.get('content', ''),
                    url=data.get('url', ''),
                    source=data.get('source', 'unknown'),
                    timestamp=data.get('timestamp', None),
                    relevance_score=data.get('relevance_score', 1.0),
                    metadata=data.get('metadata', {})
                )
                search_results.append(result)
            
            return await self.store_search_results(search_results)
            
        except Exception as e:
            self.logger.error(f"âŒ å­˜å‚¨åŸå§‹æ•°æ®å¤±è´¥: {e}")
            return False
    
    async def store_text_documents(self, documents: List[Dict[str, str]]) -> bool:
        """
        å­˜å‚¨æ–‡æœ¬æ–‡æ¡£ï¼ˆç®€åŒ–æ¥å£ï¼‰
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡æ¡£åŒ…å«titleå’Œcontent
            
        Returns:
            bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
        """
        try:
            raw_data = []
            for i, doc in enumerate(documents):
                raw_data.append({
                    'title': doc.get('title', f'Document {i+1}'),
                    'content': doc.get('content', ''),
                    'url': doc.get('url', f'doc://{i+1}'),
                    'source': 'document',
                    'relevance_score': 1.0
                })
            
            return await self.store_raw_data(raw_data)
            
        except Exception as e:
            self.logger.error(f"âŒ å­˜å‚¨æ–‡æœ¬æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """
        è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict: åŒ…å«é…ç½®å’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        return {
            "config": self.config,
            "text_processor_type": type(self.rag_processor.text_processor).__name__,
            "features": {
                "chinese_segmentation": self.config.get("enable_chinese_segmentation", False),
                "keyword_extraction": self.config.get("enable_keyword_extraction", False),
                "code_preservation": self.config.get("preserve_code_blocks", False)
            }
        }

# ä¾¿æ·å‡½æ•°
async def quick_store_search_results(search_results: List[SearchResult], config: Dict[str, Any] = None) -> bool:
    """
    å¿«é€Ÿå­˜å‚¨æœç´¢ç»“æœçš„ä¾¿æ·å‡½æ•°
    
    Args:
        search_results: æœç´¢ç»“æœåˆ—è¡¨
        config: å¯é€‰é…ç½®
        
    Returns:
        bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
    """
    manager = EnhancedStorageManager(config)
    return await manager.store_search_results(search_results)

async def quick_store_raw_data(raw_data: List[Dict[str, Any]], config: Dict[str, Any] = None) -> bool:
    """
    å¿«é€Ÿå­˜å‚¨åŸå§‹æ•°æ®çš„ä¾¿æ·å‡½æ•°
    
    Args:
        raw_data: åŸå§‹æ•°æ®åˆ—è¡¨
        config: å¯é€‰é…ç½®
        
    Returns:
        bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
    """
    manager = EnhancedStorageManager(config)
    return await manager.store_raw_data(raw_data)

async def quick_store_documents(documents: List[Dict[str, str]], config: Dict[str, Any] = None) -> bool:
    """
    å¿«é€Ÿå­˜å‚¨æ–‡æ¡£çš„ä¾¿æ·å‡½æ•°
    
    Args:
        documents: æ–‡æ¡£åˆ—è¡¨
        config: å¯é€‰é…ç½®
        
    Returns:
        bool: å­˜å‚¨æ˜¯å¦æˆåŠŸ
    """
    manager = EnhancedStorageManager(config)
    return await manager.store_text_documents(documents)

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import asyncio
    
    async def demo():
        """æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å¢å¼ºå­˜å‚¨å·¥å…·"""
        print("ğŸ› ï¸ å¢å¼ºå­˜å‚¨å·¥å…·æ¼”ç¤º")
        
        # æ–¹å¼1: ä½¿ç”¨ç®¡ç†å™¨ç±»
        manager = EnhancedStorageManager({
            "chunk_size": 600,
            "enable_chinese_segmentation": True
        })
        
        # å­˜å‚¨åŸå§‹æ•°æ®
        raw_data = [
            {
                "title": "Pythonç¼–ç¨‹åŸºç¡€",
                "content": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚Python is widely used in web development, data science, and AI.",
                "url": "https://example.com/python-basics"
            }
        ]
        
        success = await manager.store_raw_data(raw_data)
        print(f"ç®¡ç†å™¨å­˜å‚¨ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        
        # æ–¹å¼2: ä½¿ç”¨ä¾¿æ·å‡½æ•°
        documents = [
            {
                "title": "æœºå™¨å­¦ä¹ æ¦‚è¿°",
                "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ã€‚Machine learning algorithms can be supervised, unsupervised, or reinforcement learning."
            }
        ]
        
        success = await quick_store_documents(documents)
        print(f"ä¾¿æ·å‡½æ•°å­˜å‚¨ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = manager.get_processing_stats()
        print(f"å¤„ç†å™¨ç»Ÿè®¡: {stats}")
    
    asyncio.run(demo())