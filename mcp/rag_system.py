#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAGç³»ç»Ÿå¯åŠ¨è„šæœ¬å’Œé…ç½®ç®¡ç†

è¿™ä¸ªè„šæœ¬å°†æ‰€æœ‰ç»„ä»¶æ•´åˆèµ·æ¥ï¼Œæä¾›ç»Ÿä¸€çš„å¯åŠ¨å’Œé…ç½®ç®¡ç†ã€‚
ä¸“é—¨ç”¨äºå‘½ä»¤è¡Œç•Œé¢ï¼Œä¸åŒ…å«Streamlitç›¸å…³ä»£ç ã€‚
"""

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Any, Dict, List, Optional



# å¯¼å…¥æ‰€æœ‰ç»„ä»¶
try:
    # ä»mcpç›®å½•å¯¼å…¥
    from mcp_framework import MCPProcessor, QueryAnalyzer, QueryType, QueryContext
    from search_channels import GoogleSearchChannel, create_google_search_channel
    from dynamic_vector_store import DynamicVectorStore, VectorStoreManager
    
    parent_dir = str(Path(__file__).resolve().parent.parent)
    sys.path.insert(0,parent_dir)
    from enhanced_rag_processor import EnhancedRAGProcessor
    from ask_llm import TencentDeepSeekClient, get_llm_answer_deepseek
    from encoder import emb_text
    from milvus_utils import get_milvus_client
    
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print(f"å½“å‰Pythonè·¯å¾„: {sys.path}")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('rag_system.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


class RAGSystemConfig:
    """RAGç³»ç»Ÿé…ç½®ç®¡ç†"""
    
    def __init__(self, config_file: Optional[str] = None):
        """
        åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        
        Args:
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸ºconfig.json
        """
        self.config_file = config_file or "config.json"
        self.config = self._load_default_config()
        
        # å°è¯•åŠ è½½é…ç½®æ–‡ä»¶
        if os.path.exists(self.config_file):
            self._load_config_file()
        
        # ä»ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®
        self._load_from_env()
    
    def _load_default_config(self) -> Dict[str, Any]:
        """åŠ è½½é»˜è®¤é…ç½®"""
        return {
            "google_search": {
                "api_key": "",
                "search_engine_id": "",
                "timeout": 10,
                "max_results": 10
            },
            "deepseek": {
                "api_key": "",
                "base_url": "http://api.lkeap.cloud.tencent.com/v1",
                "model": "deepseek-v3-0324"
            },
            "milvus": {
                "endpoint": "./milvus_rag.db",
                "token": None,
                "collection_name": "rag_documents",
                "vector_dim": 384
            },
            "embedding": {
                "model_name": "all-MiniLM-L6-v2",
                "cache_size": 1000
            },
            "rag": {
                "similarity_threshold": 0.5,
                "max_context_length": 4000,
                "combine_search_and_vector": True,
                "enable_smart_search": True,
                "min_vector_results": 3
            }
        }
    
    def _load_config_file(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                file_config = json.load(f)
                self._deep_update(self.config, file_config)
            logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.config_file}")
        except Exception as e:
            logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    def _load_from_env(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
        env_mappings = {
            "GOOGLE_API_KEY": ["google_search", "api_key"],
            "GOOGLE_SEARCH_ENGINE_ID": ["google_search", "search_engine_id"],
            "DEEPSEEK_API_KEY": ["deepseek", "api_key"],
            "MILVUS_ENDPOINT": ["milvus", "endpoint"],
            "MILVUS_TOKEN": ["milvus", "token"]
        }
        
        for env_key, config_path in env_mappings.items():
            env_value = os.getenv(env_key)
            if env_value:
                self._set_nested_config(config_path, env_value)
                logger.info(f"ä»ç¯å¢ƒå˜é‡åŠ è½½: {env_key}")
    
    def _deep_update(self, target: dict, source: dict):
        """æ·±åº¦æ›´æ–°å­—å…¸"""
        for key, value in source.items():
            if (key in target and 
                isinstance(target[key], dict) and 
                isinstance(value, dict)):
                self._deep_update(target[key], value)
            else:
                target[key] = value
    
    def _set_nested_config(self, path: List[str], value: str):
        """è®¾ç½®åµŒå¥—é…ç½®"""
        current = self.config
        for key in path[:-1]:
            current = current[key]
        current[path[-1]] = value
    
    def save_config(self):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {self.config_file}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
    
    def get(self, *path):
        """è·å–é…ç½®å€¼"""
        current = self.config
        for key in path:
            current = current.get(key, {})
        return current
    
    def validate(self) -> bool:
        """éªŒè¯å¿…è¦çš„é…ç½®"""
        required_configs = [
            (["google_search", "api_key"], "Google API Key"),
            (["google_search", "search_engine_id"], "Google Search Engine ID"),
            (["deepseek", "api_key"], "DeepSeek API Key")
        ]
        
        missing = []
        for path, name in required_configs:
            if not self.get(*path):
                missing.append(name)
        
        if missing:
            logger.error(f"ç¼ºå°‘å¿…è¦é…ç½®: {', '.join(missing)}")
            return False
        
        return True


class RAGSystemManager:
    """RAGç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self, config: RAGSystemConfig):
        """
        åˆå§‹åŒ–ç³»ç»Ÿç®¡ç†å™¨
        
        Args:
            config: ç³»ç»Ÿé…ç½®å¯¹è±¡
        """
        self.config = config
        self.mcp_processor = None
        self.rag_processor = None
        self.search_channel = None
        self.vector_store = None
        self.deepseek_client = None
        
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # éªŒè¯é…ç½®
        if not self.config.validate():
            raise ValueError("é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¿…è¦çš„APIå¯†é’¥å’Œé…ç½®")
        
        # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        await self._init_deepseek_client()
        
        # åˆå§‹åŒ–Googleæœç´¢é€šé“
        await self._init_search_channel()
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        await self._init_vector_store()
        
        # åˆå§‹åŒ–MCPå¤„ç†å™¨
        await self._init_mcp_processor()
        
        # åˆå§‹åŒ–å¢å¼ºRAGå¤„ç†å™¨
        await self._init_rag_processor()
        
        logger.info("ğŸ‰ RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
    
    async def _init_deepseek_client(self):
        """åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯"""
        deepseek_config = {
            "api_key": self.config.get("deepseek", "api_key"),
            "base_url": self.config.get("deepseek", "base_url")
        }
        
        self.deepseek_client = TencentDeepSeekClient(
            api_key=deepseek_config["api_key"],
            base_url=deepseek_config["base_url"]
        )
        
        # æµ‹è¯•DeepSeekè¿æ¥
        try:
            test_messages = [{"role": "user", "content": "æµ‹è¯•è¿æ¥"}]
            test_response = self.deepseek_client.chat_completions_create(
                model=self.config.get("deepseek", "model"),
                messages=test_messages,
                stream=False,
                enable_search=False,
                temperature=0.1
            )
            if test_response and "choices" in test_response:
                logger.info("âœ… DeepSeek APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning("âš ï¸ DeepSeek APIè¿æ¥æµ‹è¯•è¿”å›å¼‚å¸¸æ ¼å¼")
        except Exception as e:
            logger.warning(f"âš ï¸ DeepSeek APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        
        logger.info("âœ… DeepSeekå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
    
    async def _init_search_channel(self):
        """åˆå§‹åŒ–Googleæœç´¢é€šé“"""
        self.search_channel = create_google_search_channel(
            api_key=self.config.get("google_search", "api_key"),
            search_engine_id=self.config.get("google_search", "search_engine_id"),
            config={
                "timeout": self.config.get("google_search", "timeout"),
                "max_results": self.config.get("google_search", "max_results")
            }
        )
        logger.info("âœ… Googleæœç´¢é€šé“åˆå§‹åŒ–å®Œæˆ")
    
    async def _init_vector_store(self):
        """åˆå§‹åŒ–å‘é‡å­˜å‚¨"""
        self.vector_store = DynamicVectorStore(
            milvus_endpoint=self.config.get("milvus", "endpoint"),
            milvus_token=self.config.get("milvus", "token"),
            collection_name=self.config.get("milvus", "collection_name"),
            vector_dim=self.config.get("milvus", "vector_dim")
        )
        logger.info("âœ… å‘é‡å­˜å‚¨åˆå§‹åŒ–å®Œæˆ")
    
    async def _init_mcp_processor(self):
        """åˆå§‹åŒ–MCPå¤„ç†å™¨"""
        self.mcp_processor = MCPProcessor()
        
        # æ³¨å†Œæœç´¢é€šé“åˆ°MCPå¤„ç†å™¨
        if self.search_channel:
            self.mcp_processor.register_channel(self.search_channel)
        
        logger.info("âœ… MCPå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def _init_rag_processor(self):
        """åˆå§‹åŒ–å¢å¼ºRAGå¤„ç†å™¨"""
        channels = [self.search_channel] if self.search_channel else []
        
        # æ„å»ºEnhancedRAGProcessoræœŸæœ›çš„é…ç½®æ ¼å¼
        rag_config = {
            # Milvusé…ç½®
            "milvus_endpoint": self.config.get("milvus", "endpoint"),
            "endpoint": self.config.get("milvus", "endpoint"),
            "milvus_token": self.config.get("milvus", "token"),
            "token": self.config.get("milvus", "token"),
            "vector_dim": self.config.get("milvus", "vector_dim"),
            "dimension": self.config.get("milvus", "vector_dim"),
            
            # Googleæœç´¢é…ç½®
            "google_api_key": self.config.get("google_search", "api_key"),
            "google_search_engine_id": self.config.get("google_search", "search_engine_id"),
            "search_timeout": self.config.get("google_search", "timeout"),
            
            # RAGé…ç½®
            "similarity_threshold": self.config.get("rag", "similarity_threshold"),
            "max_context_length": self.config.get("rag", "max_context_length"),
            "combine_search_and_vector": self.config.get("rag", "combine_search_and_vector"),
            "enable_smart_search": self.config.get("rag", "enable_smart_search"),
            "min_vector_results": self.config.get("rag", "min_vector_results"),
            
            # åŠŸèƒ½å¼€å…³
            "enable_search_engine": True,
            "enable_local_knowledge": True,
            "enable_news": False
        }
        
        # è¾“å‡ºRAGé…ç½®ç”¨äºè°ƒè¯•
        logger.info(f"ğŸ“‹ RAGé…ç½®ä¼ é€’: similarity_threshold={rag_config.get('similarity_threshold')}, "
                   f"enable_smart_search={rag_config.get('enable_smart_search')}, "
                   f"min_vector_results={rag_config.get('min_vector_results')}")
        
        self.rag_processor = EnhancedRAGProcessor(
            vector_store=self.vector_store,
            search_channels=channels,
            llm_client=self.deepseek_client,
            config=rag_config
        )
        logger.info("âœ… å¢å¼ºRAGå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def process_query(self, query: str, query_type: str = "factual") -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            query_type: æŸ¥è¯¢ç±»å‹ (factual, analytical, creative, conversational)
            
        Returns:
            str: æŸ¥è¯¢ç»“æœ
        """
        if not self.rag_processor:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
        
        # è½¬æ¢æŸ¥è¯¢ç±»å‹
        query_type_map = {
            "factual": QueryType.FACTUAL,
            "analytical": QueryType.ANALYTICAL,
            "creative": QueryType.CREATIVE,
            "conversational": QueryType.CONVERSATIONAL
        }
        
        query_type_enum = query_type_map.get(query_type.lower(), QueryType.FACTUAL)
        
        # åˆ›å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = QueryContext(
            query=query,
            query_type=query_type_enum,
            max_results=self.config.get("google_search", "max_results")
        )
        
        # å¤„ç†æŸ¥è¯¢
        response = await self.rag_processor.process_query(context)
        return response.answer
    
    async def process_query_stream(self, query: str, query_type: str = "factual") -> str:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢ - æµå¼è¾“å‡ºç‰ˆæœ¬
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢å†…å®¹
            query_type: æŸ¥è¯¢ç±»å‹
            
        Returns:
            str: æŸ¥è¯¢ç»“æœ
        """
        if not self.rag_processor:
            raise RuntimeError("ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨initialize()")
        
        # è½¬æ¢æŸ¥è¯¢ç±»å‹
        query_type_map = {
            "factual": QueryType.FACTUAL,
            "analytical": QueryType.ANALYTICAL,
            "creative": QueryType.CREATIVE,
            "conversational": QueryType.CONVERSATIONAL
        }
        
        query_type_enum = query_type_map.get(query_type.lower(), QueryType.FACTUAL)
        
        # åˆ›å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = QueryContext(
            query=query,
            query_type=query_type_enum,
            max_results=self.config.get("google_search", "max_results")
        )
        
        # æ˜¾ç¤ºå¤„ç†è¿›åº¦
        print("ğŸ¤– æ­£åœ¨æ€è€ƒ", end="", flush=True)
        for i in range(3):
            await asyncio.sleep(0.5)
            print(".", end="", flush=True)
        print(" ğŸ’­")
        
        # å¤„ç†æŸ¥è¯¢
        response = await self.rag_processor.process_query(context)
        
        # æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ
        answer = response.answer
        words = answer.split()
        
        print("ğŸ’¡ å›ç­”: ", end="", flush=True)
        for i, word in enumerate(words):
            print(word, end=" ", flush=True)
            if i % 5 == 4:  # æ¯5ä¸ªè¯æš‚åœä¸€ä¸‹
                await asyncio.sleep(0.1)
        
        print()  # æ¢è¡Œ
        return response.answer
    
    async def test_system(self):
        """æµ‹è¯•ç³»ç»Ÿå„ä¸ªç»„ä»¶"""
        logger.info("ğŸ§ª å¼€å§‹ç³»ç»Ÿæµ‹è¯•...")
        
        test_queries = [
            ("äººå·¥æ™ºèƒ½çš„å‘å±•å†å²", "factual"),
            ("æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŒºåˆ«", "analytical"),
            ("è¯·å†™ä¸€ä¸ªå…³äºAIçš„å°æ•…äº‹", "creative")
        ]
        
        for query, query_type in test_queries:
            logger.info(f"æµ‹è¯•æŸ¥è¯¢: {query} ({query_type})")
            try:
                answer = await self.process_query(query, query_type)
                logger.info(f"âœ… å›ç­”: {answer[:100]}...")
            except Exception as e:
                logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        
        logger.info("ğŸ‰ ç³»ç»Ÿæµ‹è¯•å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– RAGç³»ç»Ÿå¯åŠ¨å™¨")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config = RAGSystemConfig()
    
    # æ£€æŸ¥é…ç½®
    if not config.validate():
        print("\nâŒ é…ç½®éªŒè¯å¤±è´¥ï¼")
        print("\nè¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡æˆ–ç¼–è¾‘config.jsonæ–‡ä»¶ï¼š")
        print("  export GOOGLE_API_KEY='your_google_api_key'")
        print("  export GOOGLE_SEARCH_ENGINE_ID='your_search_engine_id'")
        print("  export DEEPSEEK_API_KEY='your_deepseek_api_key'")
        print("\næˆ–è€…åˆ›å»ºconfig.jsonæ–‡ä»¶åŒ…å«ä»¥ä¸Šé…ç½®")
        
        # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
        if not os.path.exists("config.json"):
            config.save_config()
            print("\nå·²åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶: config.json")
        
        return
    
    # åˆå§‹åŒ–ç³»ç»Ÿç®¡ç†å™¨
    manager = RAGSystemManager(config)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        await manager.initialize()
        
        # æµ‹è¯•ç³»ç»Ÿ
        await manager.test_system()
        
        # äº¤äº’å¼é—®ç­”
        print("\nğŸ¯ ç³»ç»Ÿå°±ç»ªï¼è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯")
        print("ğŸ’¡ æç¤ºï¼šè¾“å…¥ 'stream:é—®é¢˜' å¯ä»¥ä½¿ç”¨æµå¼è¾“å‡º")
        print("è¾“å…¥'quit'é€€å‡º:")
        
        while True:
            try:
                user_input = input("\nğŸ‘¤ æ‚¨çš„é—®é¢˜: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    break
                
                if not user_input:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
                if user_input.startswith('stream:'):
                    query = user_input[7:].strip()
                    if query:
                        await manager.process_query_stream(query)
                    continue
                
                print("ğŸ¤– æ­£åœ¨æ€è€ƒ...")
                answer = await manager.process_query(user_input)
                print(f"ğŸ’¡ å›ç­”: {answer}")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        
        print("\nğŸ‘‹ å†è§ï¼")
        
    except Exception as e:
        logger.error(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print(f"âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())
